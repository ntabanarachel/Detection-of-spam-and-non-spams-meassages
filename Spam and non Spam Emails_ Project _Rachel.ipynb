{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "c00ea50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "b33ecec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "#os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba55d47",
   "metadata": {},
   "source": [
    "# Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "190e6cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"spambase.names\")as filex:\n",
    "    reading =filex.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "ba0b6299",
   "metadata": {},
   "outputs": [],
   "source": [
    "words= [word.split(':')[0]for word in flines[33:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "ac426bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['word_freq_make',\n",
       " 'word_freq_address',\n",
       " 'word_freq_all',\n",
       " 'word_freq_3d',\n",
       " 'word_freq_our',\n",
       " 'word_freq_over',\n",
       " 'word_freq_remove',\n",
       " 'word_freq_internet',\n",
       " 'word_freq_order',\n",
       " 'word_freq_mail',\n",
       " 'word_freq_receive',\n",
       " 'word_freq_will',\n",
       " 'word_freq_people',\n",
       " 'word_freq_report',\n",
       " 'word_freq_addresses',\n",
       " 'word_freq_free',\n",
       " 'word_freq_business',\n",
       " 'word_freq_email',\n",
       " 'word_freq_you',\n",
       " 'word_freq_credit',\n",
       " 'word_freq_your',\n",
       " 'word_freq_font',\n",
       " 'word_freq_000',\n",
       " 'word_freq_money',\n",
       " 'word_freq_hp',\n",
       " 'word_freq_hpl',\n",
       " 'word_freq_george',\n",
       " 'word_freq_650',\n",
       " 'word_freq_lab',\n",
       " 'word_freq_labs',\n",
       " 'word_freq_telnet',\n",
       " 'word_freq_857',\n",
       " 'word_freq_data',\n",
       " 'word_freq_415',\n",
       " 'word_freq_85',\n",
       " 'word_freq_technology',\n",
       " 'word_freq_1999',\n",
       " 'word_freq_parts',\n",
       " 'word_freq_pm',\n",
       " 'word_freq_direct',\n",
       " 'word_freq_cs',\n",
       " 'word_freq_meeting',\n",
       " 'word_freq_original',\n",
       " 'word_freq_project',\n",
       " 'word_freq_re',\n",
       " 'word_freq_edu',\n",
       " 'word_freq_table',\n",
       " 'word_freq_conference',\n",
       " 'char_freq_;',\n",
       " 'char_freq_(',\n",
       " 'char_freq_[',\n",
       " 'char_freq_!',\n",
       " 'char_freq_$',\n",
       " 'char_freq_#',\n",
       " 'capital_run_length_average',\n",
       " 'capital_run_length_longest',\n",
       " 'capital_run_length_total']"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "24b7ecec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_conference</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.21</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.06</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.38</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0.00            0.64               0.64            0.0          0.32   \n",
       "0.21            0.28               0.50            0.0          0.14   \n",
       "0.06            0.00               0.71            0.0          1.23   \n",
       "0.00            0.00               0.00            0.0          0.63   \n",
       "0.00            0.00               0.00            0.0          0.63   \n",
       "\n",
       "      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0.00           0.00            0.00              0.00                0.00   \n",
       "0.21           0.28            0.21              0.07                0.00   \n",
       "0.06           0.19            0.19              0.12                0.64   \n",
       "0.00           0.00            0.31              0.63                0.31   \n",
       "0.00           0.00            0.31              0.63                0.31   \n",
       "\n",
       "      word_freq_order  word_freq_mail  ...  word_freq_conference  char_freq_;  \\\n",
       "0.00             0.00            0.00  ...                  0.00        0.000   \n",
       "0.21             0.94            0.21  ...                  0.00        0.132   \n",
       "0.06             0.25            0.38  ...                  0.01        0.143   \n",
       "0.00             0.63            0.31  ...                  0.00        0.137   \n",
       "0.00             0.63            0.31  ...                  0.00        0.135   \n",
       "\n",
       "      char_freq_(  char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0.00          0.0        0.778        0.000        0.000        3.756   \n",
       "0.21          0.0        0.372        0.180        0.048        5.114   \n",
       "0.06          0.0        0.276        0.184        0.010        9.821   \n",
       "0.00          0.0        0.137        0.000        0.000        3.537   \n",
       "0.00          0.0        0.135        0.000        0.000        3.537   \n",
       "\n",
       "      capital_run_length_average  capital_run_length_longest  \\\n",
       "0.00                          61                         278   \n",
       "0.21                         101                        1028   \n",
       "0.06                         485                        2259   \n",
       "0.00                          40                         191   \n",
       "0.00                          40                         191   \n",
       "\n",
       "      capital_run_length_total  \n",
       "0.00                         1  \n",
       "0.21                         1  \n",
       "0.06                         1  \n",
       "0.00                         1  \n",
       "0.00                         1  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('spambase (1).data',names= words)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09cc3f7",
   "metadata": {},
   "source": [
    "# FEATURE EXPLORATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "f6b8631a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_conference</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.213015</td>\n",
       "      <td>0.280656</td>\n",
       "      <td>0.065425</td>\n",
       "      <td>0.312223</td>\n",
       "      <td>0.095901</td>\n",
       "      <td>0.114208</td>\n",
       "      <td>0.105295</td>\n",
       "      <td>0.090067</td>\n",
       "      <td>0.239413</td>\n",
       "      <td>0.059824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038575</td>\n",
       "      <td>0.139030</td>\n",
       "      <td>0.016976</td>\n",
       "      <td>0.269071</td>\n",
       "      <td>0.075811</td>\n",
       "      <td>0.044238</td>\n",
       "      <td>5.191515</td>\n",
       "      <td>52.172789</td>\n",
       "      <td>283.289285</td>\n",
       "      <td>0.394045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.290575</td>\n",
       "      <td>0.504143</td>\n",
       "      <td>1.395151</td>\n",
       "      <td>0.672513</td>\n",
       "      <td>0.273824</td>\n",
       "      <td>0.391441</td>\n",
       "      <td>0.401071</td>\n",
       "      <td>0.278616</td>\n",
       "      <td>0.644755</td>\n",
       "      <td>0.201545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243471</td>\n",
       "      <td>0.270355</td>\n",
       "      <td>0.109394</td>\n",
       "      <td>0.815672</td>\n",
       "      <td>0.245882</td>\n",
       "      <td>0.429342</td>\n",
       "      <td>31.729449</td>\n",
       "      <td>194.891310</td>\n",
       "      <td>606.347851</td>\n",
       "      <td>0.488698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.588000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.276000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.706000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.280000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>42.810000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>5.260000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>2.610000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.385000</td>\n",
       "      <td>9.752000</td>\n",
       "      <td>4.081000</td>\n",
       "      <td>32.478000</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.829000</td>\n",
       "      <td>1102.500000</td>\n",
       "      <td>9989.000000</td>\n",
       "      <td>15841.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "count     4601.000000        4601.000000    4601.000000   4601.000000   \n",
       "mean         0.213015           0.280656       0.065425      0.312223   \n",
       "std          1.290575           0.504143       1.395151      0.672513   \n",
       "min          0.000000           0.000000       0.000000      0.000000   \n",
       "25%          0.000000           0.000000       0.000000      0.000000   \n",
       "50%          0.000000           0.000000       0.000000      0.000000   \n",
       "75%          0.000000           0.420000       0.000000      0.380000   \n",
       "max         14.280000           5.100000      42.810000     10.000000   \n",
       "\n",
       "       word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "count    4601.000000     4601.000000       4601.000000         4601.000000   \n",
       "mean        0.095901        0.114208          0.105295            0.090067   \n",
       "std         0.273824        0.391441          0.401071            0.278616   \n",
       "min         0.000000        0.000000          0.000000            0.000000   \n",
       "25%         0.000000        0.000000          0.000000            0.000000   \n",
       "50%         0.000000        0.000000          0.000000            0.000000   \n",
       "75%         0.000000        0.000000          0.000000            0.000000   \n",
       "max         5.880000        7.270000         11.110000            5.260000   \n",
       "\n",
       "       word_freq_order  word_freq_mail  ...  word_freq_conference  \\\n",
       "count      4601.000000     4601.000000  ...           4601.000000   \n",
       "mean          0.239413        0.059824  ...              0.038575   \n",
       "std           0.644755        0.201545  ...              0.243471   \n",
       "min           0.000000        0.000000  ...              0.000000   \n",
       "25%           0.000000        0.000000  ...              0.000000   \n",
       "50%           0.000000        0.000000  ...              0.000000   \n",
       "75%           0.160000        0.000000  ...              0.000000   \n",
       "max          18.180000        2.610000  ...              4.385000   \n",
       "\n",
       "       char_freq_;  char_freq_(  char_freq_[  char_freq_!  char_freq_$  \\\n",
       "count  4601.000000  4601.000000  4601.000000  4601.000000  4601.000000   \n",
       "mean      0.139030     0.016976     0.269071     0.075811     0.044238   \n",
       "std       0.270355     0.109394     0.815672     0.245882     0.429342   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.065000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.188000     0.000000     0.315000     0.052000     0.000000   \n",
       "max       9.752000     4.081000    32.478000     6.003000    19.829000   \n",
       "\n",
       "       char_freq_#  capital_run_length_average  capital_run_length_longest  \\\n",
       "count  4601.000000                 4601.000000                 4601.000000   \n",
       "mean      5.191515                   52.172789                  283.289285   \n",
       "std      31.729449                  194.891310                  606.347851   \n",
       "min       1.000000                    1.000000                    1.000000   \n",
       "25%       1.588000                    6.000000                   35.000000   \n",
       "50%       2.276000                   15.000000                   95.000000   \n",
       "75%       3.706000                   43.000000                  266.000000   \n",
       "max    1102.500000                 9989.000000                15841.000000   \n",
       "\n",
       "       capital_run_length_total  \n",
       "count               4601.000000  \n",
       "mean                   0.394045  \n",
       "std                    0.488698  \n",
       "min                    0.000000  \n",
       "25%                    0.000000  \n",
       "50%                    0.000000  \n",
       "75%                    1.000000  \n",
       "max                    1.000000  \n",
       "\n",
       "[8 rows x 57 columns]"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "34c06529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word_freq_make                0\n",
       "word_freq_address             0\n",
       "word_freq_all                 0\n",
       "word_freq_3d                  0\n",
       "word_freq_our                 0\n",
       "word_freq_over                0\n",
       "word_freq_remove              0\n",
       "word_freq_internet            0\n",
       "word_freq_order               0\n",
       "word_freq_mail                0\n",
       "word_freq_receive             0\n",
       "word_freq_will                0\n",
       "word_freq_people              0\n",
       "word_freq_report              0\n",
       "word_freq_addresses           0\n",
       "word_freq_free                0\n",
       "word_freq_business            0\n",
       "word_freq_email               0\n",
       "word_freq_you                 0\n",
       "word_freq_credit              0\n",
       "word_freq_your                0\n",
       "word_freq_font                0\n",
       "word_freq_000                 0\n",
       "word_freq_money               0\n",
       "word_freq_hp                  0\n",
       "word_freq_hpl                 0\n",
       "word_freq_george              0\n",
       "word_freq_650                 0\n",
       "word_freq_lab                 0\n",
       "word_freq_labs                0\n",
       "word_freq_telnet              0\n",
       "word_freq_857                 0\n",
       "word_freq_data                0\n",
       "word_freq_415                 0\n",
       "word_freq_85                  0\n",
       "word_freq_technology          0\n",
       "word_freq_1999                0\n",
       "word_freq_parts               0\n",
       "word_freq_pm                  0\n",
       "word_freq_direct              0\n",
       "word_freq_cs                  0\n",
       "word_freq_meeting             0\n",
       "word_freq_original            0\n",
       "word_freq_project             0\n",
       "word_freq_re                  0\n",
       "word_freq_edu                 0\n",
       "word_freq_table               0\n",
       "word_freq_conference          0\n",
       "char_freq_;                   0\n",
       "char_freq_(                   0\n",
       "char_freq_[                   0\n",
       "char_freq_!                   0\n",
       "char_freq_$                   0\n",
       "char_freq_#                   0\n",
       "capital_run_length_average    0\n",
       "capital_run_length_longest    0\n",
       "capital_run_length_total      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CHECKING  FOR NULL VALUES IN OUR DATASET\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "2da2b925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['word_freq_make',\n",
       " 'word_freq_address',\n",
       " 'word_freq_all',\n",
       " 'word_freq_3d',\n",
       " 'word_freq_our',\n",
       " 'word_freq_over',\n",
       " 'word_freq_remove',\n",
       " 'word_freq_internet',\n",
       " 'word_freq_order',\n",
       " 'word_freq_mail',\n",
       " 'word_freq_receive',\n",
       " 'word_freq_will',\n",
       " 'word_freq_people',\n",
       " 'word_freq_report',\n",
       " 'word_freq_addresses',\n",
       " 'word_freq_free',\n",
       " 'word_freq_business',\n",
       " 'word_freq_email',\n",
       " 'word_freq_you',\n",
       " 'word_freq_credit',\n",
       " 'word_freq_your',\n",
       " 'word_freq_font',\n",
       " 'word_freq_000',\n",
       " 'word_freq_money',\n",
       " 'word_freq_hp',\n",
       " 'word_freq_hpl',\n",
       " 'word_freq_george',\n",
       " 'word_freq_650',\n",
       " 'word_freq_lab',\n",
       " 'word_freq_labs',\n",
       " 'word_freq_telnet',\n",
       " 'word_freq_857',\n",
       " 'word_freq_data',\n",
       " 'word_freq_415',\n",
       " 'word_freq_85',\n",
       " 'word_freq_technology',\n",
       " 'word_freq_1999',\n",
       " 'word_freq_parts',\n",
       " 'word_freq_pm',\n",
       " 'word_freq_direct',\n",
       " 'word_freq_cs',\n",
       " 'word_freq_meeting',\n",
       " 'word_freq_original',\n",
       " 'word_freq_project',\n",
       " 'word_freq_re',\n",
       " 'word_freq_edu',\n",
       " 'word_freq_table',\n",
       " 'word_freq_conference',\n",
       " 'char_freq_;',\n",
       " 'char_freq_(',\n",
       " 'char_freq_[',\n",
       " 'char_freq_!',\n",
       " 'char_freq_$',\n",
       " 'char_freq_#',\n",
       " 'capital_run_length_average',\n",
       " 'capital_run_length_longest',\n",
       " 'capital_run_length_total']"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "ffa53ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word_freq_make                float64\n",
       "word_freq_address             float64\n",
       "word_freq_all                 float64\n",
       "word_freq_3d                  float64\n",
       "word_freq_our                 float64\n",
       "word_freq_over                float64\n",
       "word_freq_remove              float64\n",
       "word_freq_internet            float64\n",
       "word_freq_order               float64\n",
       "word_freq_mail                float64\n",
       "word_freq_receive             float64\n",
       "word_freq_will                float64\n",
       "word_freq_people              float64\n",
       "word_freq_report              float64\n",
       "word_freq_addresses           float64\n",
       "word_freq_free                float64\n",
       "word_freq_business            float64\n",
       "word_freq_email               float64\n",
       "word_freq_you                 float64\n",
       "word_freq_credit              float64\n",
       "word_freq_your                float64\n",
       "word_freq_font                float64\n",
       "word_freq_000                 float64\n",
       "word_freq_money               float64\n",
       "word_freq_hp                  float64\n",
       "word_freq_hpl                 float64\n",
       "word_freq_george              float64\n",
       "word_freq_650                 float64\n",
       "word_freq_lab                 float64\n",
       "word_freq_labs                float64\n",
       "word_freq_telnet              float64\n",
       "word_freq_857                 float64\n",
       "word_freq_data                float64\n",
       "word_freq_415                 float64\n",
       "word_freq_85                  float64\n",
       "word_freq_technology          float64\n",
       "word_freq_1999                float64\n",
       "word_freq_parts               float64\n",
       "word_freq_pm                  float64\n",
       "word_freq_direct              float64\n",
       "word_freq_cs                  float64\n",
       "word_freq_meeting             float64\n",
       "word_freq_original            float64\n",
       "word_freq_project             float64\n",
       "word_freq_re                  float64\n",
       "word_freq_edu                 float64\n",
       "word_freq_table               float64\n",
       "word_freq_conference          float64\n",
       "char_freq_;                   float64\n",
       "char_freq_(                   float64\n",
       "char_freq_[                   float64\n",
       "char_freq_!                   float64\n",
       "char_freq_$                   float64\n",
       "char_freq_#                   float64\n",
       "capital_run_length_average      int64\n",
       "capital_run_length_longest      int64\n",
       "capital_run_length_total        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a578503f",
   "metadata": {},
   "source": [
    "<B># Extracting Independent and dependent VariableA</B>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "07370881",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.iloc[0:,0:56].values\n",
    "y=df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "15f14dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.400e-01, 6.400e-01, 0.000e+00, ..., 3.756e+00, 6.100e+01,\n",
       "        2.780e+02],\n",
       "       [2.800e-01, 5.000e-01, 0.000e+00, ..., 5.114e+00, 1.010e+02,\n",
       "        1.028e+03],\n",
       "       [0.000e+00, 7.100e-01, 0.000e+00, ..., 9.821e+00, 4.850e+02,\n",
       "        2.259e+03],\n",
       "       ...,\n",
       "       [0.000e+00, 3.000e-01, 0.000e+00, ..., 1.404e+00, 6.000e+00,\n",
       "        1.180e+02],\n",
       "       [0.000e+00, 0.000e+00, 0.000e+00, ..., 1.147e+00, 5.000e+00,\n",
       "        7.800e+01],\n",
       "       [0.000e+00, 6.500e-01, 0.000e+00, ..., 1.250e+00, 5.000e+00,\n",
       "        4.000e+01]])"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "05a7287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset into training and test set.\n",
    "#from here we can see that after spliting, we gave our test data =25%, meaning that our remaing data which is training has 75%\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state= 144)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "e966a923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.   ,   0.   ,   0.   , ...,   1.36 ,   3.   ,  34.   ],\n",
       "       [  0.   ,   0.   ,   0.   , ...,   4.333,  13.   ,  78.   ],\n",
       "       [  0.25 ,   0.   ,   0.   , ...,   3.181,  32.   , 210.   ],\n",
       "       ...,\n",
       "       [  0.   ,   0.   ,   0.   , ...,   3.333,  10.   ,  30.   ],\n",
       "       [  0.   ,   0.4  ,   0.   , ...,   1.727,  11.   , 190.   ],\n",
       "       [  0.   ,   0.   ,   0.   , ...,   2.446,  11.   , 115.   ]])"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad332cfa",
   "metadata": {},
   "source": [
    "* as we can see from this training data is not scaled since we want to compare  the difference between scaled and unscaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "afa90d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3680, 56)"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for rows and columns\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "f5a954d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3680,)"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743211e8",
   "metadata": {},
   "source": [
    "<b> Fitting K-nearest neighbor to our training data by choosing kvalue=8 </b>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "1c1caf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "817ecb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model=KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "f5d1ac87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the model\n",
    "knn_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "c2ad758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## predicting the Test set Results\n",
    "y_pred=knn_model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62a77b4",
   "metadata": {},
   "source": [
    "# EVALUATION\n",
    "\n",
    "*  I am going to test Test Accuracy of the result for KNN Algorithm by  using both  the Confusion matrix and accuracy score, and classification report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "ffc25378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[482,  76],\n",
       "       [108, 255]], dtype=int64)"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5f3756",
   "metadata": {},
   "source": [
    " * out of 100: TP+TN= 482+255=737 FP+FN=482+255=737\n",
    "\n",
    "* we can interpret that − 108+76= 184 (Correct Output), − and 1108+76= 184(Incorrect Output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "2ebe454a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.8002171552660152\n"
     ]
    }
   ],
   "source": [
    "#Accuracy = (TP+TN)/total\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"accuracy score:\", accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7373ea",
   "metadata": {},
   "source": [
    "• Accuracy measures the proportion of true results to total cases.\n",
    "− Aim for a high accuracy rate.\n",
    "• Accuracy is a common evaluation metric for classification problems.\n",
    "It’s the number of correct predictions made as a ratio of all predictions\n",
    "made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "d88c408f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifcation report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83       558\n",
      "           1       0.75      0.69      0.72       363\n",
      "\n",
      "    accuracy                           0.79       921\n",
      "   macro avg       0.78      0.77      0.77       921\n",
      "weighted avg       0.79      0.79      0.79       921\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "matrix = classification_report(y_test,y_pred)\n",
    "print(\"classifcation report:\",matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "e7754743",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting model with decesion tree algorithm and try compare its accuracy with the previous model algorithm which is KNN\n",
    "# defining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "c3489281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "Tree_model=DecisionTreeClassifier()\n",
    "Tree_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "aac4eda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting\n",
    "y_predict_tree=Tree_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "b0f05d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9044516829533116"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_predict_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "cb27b2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifcation report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       558\n",
      "           1       0.88      0.88      0.88       363\n",
      "\n",
      "    accuracy                           0.90       921\n",
      "   macro avg       0.90      0.90      0.90       921\n",
      "weighted avg       0.90      0.90      0.90       921\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "matrix = classification_report(y_test,y_predict_tree)\n",
    "print(\"classifcation report:\",matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "d316199b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[514,  44],\n",
       "       [ 44, 319]], dtype=int64)"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "accuracy =confusion_matrix(y_test,y_predict_tree)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12621cb5",
   "metadata": {},
   "source": [
    "# After working with unscaled data,I am going to work with scaled data and compare their accuracy from KNN and decision tree algorithms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "7e80db67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.00032683, 0.00090785,\n",
       "        0.00208333],\n",
       "       [0.        , 0.        , 0.        , ..., 0.00302587, 0.00544712,\n",
       "        0.00486111],\n",
       "       [0.017507  , 0.        , 0.        , ..., 0.00198003, 0.01407172,\n",
       "        0.01319444],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.00211802, 0.00408534,\n",
       "        0.00183081],\n",
       "       [0.        , 0.07843137, 0.        , ..., 0.00066001, 0.00453926,\n",
       "        0.01193182],\n",
       "       [0.        , 0.        , 0.        , ..., 0.00131276, 0.00453926,\n",
       "        0.00719697]])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data scaling \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "minimax_model=MinMaxScaler()\n",
    "x_train_scale=minimax_model.fit_transform(x_train)\n",
    "x_train_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "7cc0f67c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.00039757],\n",
       "       [0.        , 0.        , 0.        , ..., 0.00748   , 0.00140168,\n",
       "        0.02415267],\n",
       "       [0.        , 0.        , 0.        , ..., 0.003732  , 0.00060072,\n",
       "        0.00566544],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.005468  , 0.00230276,\n",
       "        0.0646059 ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.018152  , 0.00400481,\n",
       "        0.00705695],\n",
       "       [0.02871148, 0.04405286, 0.        , ..., 0.0026    , 0.00140168,\n",
       "        0.0172945 ]])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_scale=minimax_model.fit_transform(x_test)\n",
    "x_test_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c8044f",
   "metadata": {},
   "source": [
    " # KNN algorithm in scaled  data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "655e95ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the model using KNN\n",
    "knn_model.fit(x_train_scale,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "763bd14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#predicting model\n",
    "y_pred_scale=knn_model.predict(x_test_scale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "436848b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[516,  42],\n",
       "       [ 60, 303]], dtype=int64)"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,y_pred_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "e2b4c73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8892508143322475"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b61604",
   "metadata": {},
   "source": [
    "   # Decision tree in scaled  data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "2a077a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "Tree_model=DecisionTreeClassifier()\n",
    "Tree_model.fit(x_train_scale,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "70048373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting\n",
    "y_predict_tree=Tree_model.predict(x_test_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "e24b2357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[516,  42],\n",
       "       [ 60, 303]], dtype=int64)"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking accuracy for scaled data\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,y_pred_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "5f074d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7915309446254072"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_predict_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f39408",
   "metadata": {},
   "source": [
    "# Performing  feauture importance \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "123d61ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9243478260869565, 0.9131190269331017)"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature selection\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "xnew = SelectKBest(chi2, k=23).fit_transform(x,y)\n",
    "\n",
    "# split into test and training\n",
    "xtrain,xtest,ytrain,ytest= train_test_split(xnew,y,test_size=0.25,random_state=42)\n",
    "\n",
    "# scaling the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()\n",
    "xtrain = scale.fit_transform(xtrain)\n",
    "xtest = scale.transform(xtest)\n",
    "\n",
    "# fitting the model\n",
    "knn=KNeighborsClassifier(n_neighbors=13)\n",
    "knn.fit(xtrain, ytrain)\n",
    "ypred = knn.predict(xtest)\n",
    "ypredtrain = knn.predict(xtrain)\n",
    "\n",
    "# accuracy\n",
    "accuracy = accuracy_score(ytest,ypred)\n",
    "accuracytrain = accuracy_score(ytrain,ypredtrain)\n",
    "accuracytrain, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c0a2d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0151335e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
